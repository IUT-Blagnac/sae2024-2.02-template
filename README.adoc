= SAÉ 2.02
:icons: font
:numbered:
:toc: left
:toc-title: Sommaire
:toclevels: 1
:toc!:
// Antora 
// => traduction automatique fr/uk
// => niveau de guidage
//include:definitions.txt (glossaire des termes du BUT comme SAE)

// Specific to GitHub
ifdef::env-github[]
:toc:
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:graduation-icon: :mortar_board:
:cogs-icon: :writing_hand:
:beginner: :arrow_right:
:advanced: :arrow_upper_right:
:expert: :arrow_up:
:dollar: :dollar:
:git: link:{giturl}[git]
:us-icon: :us:
:fr-icon: :fr:
endif::[]

// Local variables

:codacy: https://www.codacy.com[Codacy]
:joular: https://www.noureddine.org/research/joular[Joular]
:RLE: https://fr.wikibooks.org/wiki/Compression_de_donn%C3%A9es/Run-length_encoding[Run-Length Encoding]

== Auteur(s)

=== Du sujet...
- mailto:bruel@irit.fr[Jean-Michel Bruel]
- Version: 2024.01 (BUT1 2024)
//- Kata length: 12 hours
- Durée :  18 heures (1 TD et 4 TP encadrés, 7 créneaux en autonomie)

=== De la solution...

* LAST NAME : DOE
* First name : John
* TD group : 
- [ ] 1
- [x] 2
- [ ] 3
- [ ] 4

// == Objectives
== Objectifs

L'objectif de cette SAÉ (**S**ituation d'**A**pprentissage et d'**É**valuation) est d'approfondir la réflexion sur l'approche algorithmique des problèmes rencontrés pendant les phases de développement. (cf. link:docs/sae2.02.pdf[]).

Plus précisément :

  - Participer à un petit "concours" de codage
  - Lire, comprendre et évaluer un code qui n'est pas le sien
  - Comparer des algorithmes sur un critère précis
  - Justifier de manière objective ses comparaisons et son classement

// == Documents fournis
== Description

Cette SAÉ se déroule en 2 phases.

=== Phase 1 : concours d'algorithme (20% seulement de la note)

Vous allez devoir soumettre individuellement un algorithme qui résout un problème simple (niveau BUT S1) mais qui peut se régler avec plusieurs solutions différentes. 
Vous avez la semaine 24 (encadrée, et questions sur Discord bienvenues pendant les séances libres) pour réaliser et soumettre votre (ou vos) solutions. 

WARNING: Cette 1ère phase est **individuelle**.

Le problème consiste à simplement implémenter l'algorithme de compression {RLE} (RLE).

TIP: Voir aussi cette page : https://fr.wikipedia.org/wiki/Codage_par_plages

Exemple d'input::
`"WWWWWWWWWBWWWWWWWWBBBWWWBWWWWWWW"`

Exemple d'ouput::
`"9W1B8W3B3W1B7W"`

Les *contraintes* sont les suivantes :

- votre algorithme doit être écrit dans l'un des langages suivants au choix : java, python ou C
- il doit permettre aux test JUnit fournis de passer (respect donc des noms de classes, méthodes ou fonctions en conséquence). Le choix du nom de la fonction n'est donc pas libre!
- le texte à compresser est donné sous forme d'une chaîne de caractères (sans accents pour éviter les soucis)
- le texte compressé est aussi retourné sous forme d'une chaîne de caractères.

Vu qu'il existe de nombreuses façons de résoudre ce problème, vous devrez soumettre, pour chaque catégorie, votre meilleure solution.

Simplicité::
  Ici il s'agit de faire un code facile à maintenir, lisible par des humains.  Pas forcément efficace, mais très facile à lire et à réutiliser. Toute méthode de `java.util` existante est autorisée.

Efficacité::
  Peu importe le code source, c'est l'efficacité de son exécution qui est recherchée (complexité maîtrisée, temps d'exécution minimal, ...). 
Ici aucune méthode complexe (de type `split()` ou `sort()`) ne devra être utilisée (contrairement à celles de type `size()` ou `length()` qui sont autorisées).

Sobriété numérique::
  L'algorithme consomme le moins de ressources possible (mémoire, calcul, ...).

NOTE: Vous pouvez soumettre plusieurs algorithmes dans plusieurs catégories pour maximiser vos chances de gagner le concours et obtenir des points bonus.

WARNING: Nous sommes conscients que vous pouvez vous aider de Copilot, ChatGPT ou des codes de vos collègues, mais la notation qui a le plus gros coefficient est l'oral final. Si vous êtes incapable d'expliquer vos propres résultats, cette note s'approchera de 0.

==== Dépôt

Vous devrez déposer sur https://webetud.iut-blagnac.fr/mod/assign/view.php?id=28090[WebEtud], avant *vendredi 14 juin à 23h59*, vos fichiers de solutions en les nommant ainsi (pour le dépôt) : `[efficacite|sobriete|simplicite].[java|c|py]`.

Par exemple pour votre algorithme java en simplicité, vous le déposerez avec le nom `simplicite.java`.

[NOTE]
====
- Si vous en déposez plusieurs d'une même catégorie/type, numérotez-lez (`simplicite1.java` et `simplicite2.java`)
- Ne mettez aucun commentaire ou élément qui *permettent de vous identifier* dans le code!
- Pensez à déposer aussi les `.h` pour les fonctions C.
====

=== Phase 2 : comparaison et évaluation des solutions

Dans cette deuxième phase, (avec séances encadrées et libres), vous devrez comparer des solutions entre elles, et les classer en justifiant vos analyses.

WARNING: Cette deuxième phase est en binôme (de votre choix)

Vous vous verrez affecter, pour *chaque* catégorie d'algorithmes (Simplicité, Efficacité, Sobriété) un certain nombre de solutions au hasard parmi celles soumises en phase 1.

Il vous faudra évaluer chaque algorithme selon des critères et les classer ensuite.

NOTE: On vous impose au minimum les critères ci-dessous mais vous pourrez en rajouter.
À vous de les utiliser judicieusement pour les catégories les plus appropriées.

=== Critères de comparaison

Lisibilité du code::
  Ce critère est subjectif. Il se base sur la facilité à comprendre ce que fait le code.
Qualité du code::
  Vous utiliserez des outils open source de mesure de qualité de code (e.g., {codacy}).
Efficacité::
  Il s'agit d'évaluer la complexité algorithmique de la solution (`O(n^2)` ou `O(nlog(n))`). Si on double par exemple la taille de la donnée en entrée, est-ce qu'on double le temps de calcul ?
Sobriété numérique::
  Cela devient un critère de plus en plus important. Certains outils permettent de donner une mesure de la consommation en ressources d'un algorithme (e.g., {joular}).
Temps d'exécution::
  Il s'agit de mesurer le temps d'exécution.
+
WARNING: Il conviendra de prendre des mesures sur des données plus ou moins grandes, certains algorithmes étant plus rapides que d'autres en fonction de la taille des données en entrée (beaucoup de mots dans la chaîne initiale), ou de leur variété (beaucoup de grands mots).

// == Deliverables
== Livrables

Vous utiliserez le dépôt initial qui vous aura été attribué via classroom pour pousser vos codes et vos livrables (en plus des dépôts moodle).
//https://classroom.github.com/a/UXmIvsjX

=== Phase 1 (deadline : **vendredi 14 juin 2024** à minuit)

* [ ] Votre ou vos algorithmes en précisant les éléments du tableau ci-dessous :

[options="header"]
|==========================================================================
| #    | lien                                                     | langage  | catégorie 
| 1    | link:src/main/java/exercice/Exercice1.java[meilleur java]| Java     | Simplicité
| 2    | link:src/main/java/exercice/Exercice2.java[meilleur C]    | C     | Efficacité
| ...  | ...                                                      | ...      | ...      
|==========================================================================

=== Phase 2 (deadline : **vendredi 21 juin 2024** à minuit)

* [ ] Le rapport d'évaluation des algorithmes (e.g., asciidoc ou PDF). Pour chaque catégorie, vous devrez désigner qui est 1er, 2ème, 3ème, ... (avec possibilité d’ex-aequo si le hasard vous a attribué des algos similaires). Il doit se trouver dans le répertoire `rapport` de votre dépôt.
* [ ] Les codes de test, d'évaluation ou de mesure. Ils doivent se trouver dans le répertoire `analyse` de votre dépôt.
* [ ] Les références des librairies/outils utilisés (pour ceux non fournis). Elles doivent être listées dans la sous-section (Références) ci-dessous.
* [ ] La chaîne de compilation et exécutable, ou paquetage selon les standards du langage (comment exécuter vos codes d'évaluation). Cette description doit se trouver dans vos rapports.

WARNING: Les répertoires et fichiers existants devront être complétés et mis à jour sans être renommés. Les binaires de compilation (répertoire `bin` ou `target` par exemple) ne devront pas être poussés sur le dépôt.

=== Pré-requis

Voici les pré-requis pour exécuter nos codes d'évaluation.

- Java v.x.y.z
- ...

=== Reproductibilité

- Pour reproduire nos analyses :
. Installez X
. Lancez Y
. ...

=== Références

- link:http://xyz[Mon super outil XYZ]
- ...

== Généralités, notation de la SAÉ et résultat du concours

=== Généralités

- Vous pouvez vous entraider pour les outils d'analyse et de performance, voire vous inspirer de ChatGPT
- N'hésitez pas à solliciter vos enseignants des ressources impliquées par cette SAÉ (salon https://discord.com/channels/357245708014977034/1105770228589277224[#sae_2_02_qualité] du serveur discord).

=== Notation

- **80%** de la notation portera sur votre rapport de la phase 2 et vos analyses (véracité, pertinence, qualité, ajout de critères pertinents, ...). L'évaluation comportera un oral en semaine 25 (lors des séances encadrées).
- **20%** de la notation portera sur le classement de votre algorithme de la phase 1 (pertinence de la catégorie choisie, évaluation/classement par les pairs, ...)
- **Bonus** pour les 10 premiers de chaque catégorie du concours de codage
- **Bonus** pour ceux qui auront proposés plusieurs algos différents (indépendamment de leur classement final)
- **Bonus** supplémentaire pour ceux qui auront proposés des versions en langages différents de leur(s) algo(s)  (indépendamment de leur classement final)

